---
title:  "[TAcademy] Kaggle 데이터분석 입문 05강 타이타닉 생존자 예측 문제(EDA, Feature Engineering)"
date: 2020-05-17 21:34

toc: true

---

# Kaggle 타이타닉 생존자 예측 문제 

Modeling Workflow
: 외우려고 하지 말고, 분석과정이 손에 익을때까지 꾸준히 연습해야

: 끝없는 무한반복으로 ML 사고방식이 머리에 박혀야 

_*benchmarking notebook*_

- title : EDA To Prediction(DieTanic)
- url : https://www.kaggle.com/ash316/eda-to-prediction-dietanic
- 

## Process of making a Predictive Model

https://www.kaggle.com/ash316/eda-to-prediction-dietanic/notebook#Ensembling

- model을 직접 만드는게 아닌 이상 Modeling은 사실 몇줄이면 끝난다
- 데이터를 제대로 분석해서 model을 잘 만드는 게 중요

### 01. import dataset & packages to need

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# plt.style.use('fivethirtyeight)
plt.style.use('seaborn')

from warnings import filterwarnings
filterwarnings('ignore')

%matplotlib inline
```

```python
data=pd.read_csv('../input/train.csv')
```

---

### 02. data 탐색

```python
data.head()
```

#### null data

```python
data.isnull().sum()
```

- 의미 있는 경우도 종종 있음
- null data라고해서 항상 버리는 건 아님

#### survived numbers

생존자 수 시각화

- 시각화 관련 methods 너무 많다
- 외우려 하지 말고 Googling 적극 활용
  - 특히 Pandas documentation
  - StackOverFlow
  - 자주 쓰는 용어들에 익숙해야
  - 질문하기 전 최소 30분 ~ 1시간은 googling을 해보자, 검색하는 과정에서 배우는게 많다

```python
f, ax = plt.subplots(nrows=1, ncols=2, figsize=(18,8))

data['Survived'].value_counts().plot.pie(explode=[0,0.1], autopct='%1.1f%%', ax=ax[0], shadow=True)
ax[0].set_title('Survived')
ax[0].set_ylabel('')

sns.countplot('Survived', data=data, ax=ax[1])
ax[1].set_title('Survived')
plt.show()
```

60:40 정도면 굉장히 깔끔한 데이터

90:10, 99:1 도 수두룩하다

#### Types of Features

- Categorical Features
- Ordinal Features
- Continuous Features

data type에 따라 처리하는 방식도 다름!!

- 특히 string data, categorical data는 다루기 쉽지 않음
- category encoders 아주 다양함

*_Sex ; categorical features_*

table 형식으로 조회

```python
data.groupby(['Sex', 'Survived'])['Survived'].count()
```

plot 형식으로 시각화

- count / mean plot
- 특히 binary classification 인 경우, 그릴만한 plot 종류는 정해져 있고, 미리 함수화해서 코드를 갖고 있으면 좋다

```python
f, ax = plt.subplots(1,2,figsize = (18,8))

data[['Sex','Survived']].groupby(['Sex']).mean().plot.bar(ax = ax[0])
ax[0].set_title('Survived vs. Sex')

sns.countplot('Sex', hue = 'Survived', data = data, ax = ax[1])
ax[1].set_title('Sex : Survived vs. Dead')

plt.show()
```

*_Pclass ; Ordinal Feature_*

- 순서 있는 label encoding
- 순서가 있는 feature는 labeling을 해도 된다

```python
pd.crosstab(
    index,
    columns,
    values=None,
    rownames=None,
    colnames=None,
    aggfunc=None,
    margins=False,
    margins_name: str = 'All',
    dropna: bool = True,
    normalize=False,
) -> 'DataFrame'
```

```python
pd.crosstab(data.Pclass, data.Survived, margins=True).style.background_gradient(cmap='summer_r')
```

visualization

- 시각화의 중요성
- 3차원 : x, y, color
- 4차원 : x, y, color, size

```python
f, ax = plt.subplots(1,2, figsize=(18,8))

data['Pclass'].value_counts().plot.bar(color=['#CD7F32','#FFDF00','#D3D3D3'], ax=ax[0])
ax[0].set_title('Number of Passengers By Pclass')
ax[0].set_ylabel('Count')

sns.countplot('Pclass', hue='Survived', data=data, ax=ax[1])
ax[1].set_title('Pclass: Survived vs. Dead')
plt.show()
```

3차원 데이터 시각화

```python
sns.factorplot('Pclass', 'Survived', hue='Sex', data=data)
plt.show()
```

*_Age ; Continuous Feature_*

- statics : min, max, std, mean

    ```python
    print (data.Age.max())
    print (data.Age.min())
    print (data.Age.mean())
    ```

visualization

```python
f, ax = plt.subplots(1,2,figsize=(18,8))

sns.violinplot('Pclass','Age',hue='Survived',data=data, split=True, ax=ax[0])
ax[0].set_title('Pclass - Age -Survived')
ax[0].set_yticks(range(0,110,10))

sns.swarmplot('Sex','Age',hue='Survived',data=data, split=True, ax=ax[1])
ax[1].set_title('Sex - Age - Survived')
ax[1].set_yticks(range(0,110,10))
plt.show()
```

numeric data는 categorical data로 변형시킬 수 있다

'Age' column 에 null data 177개, 꼭 null data를 대체시킬 필요는 없다

여기서는 이름 형태를 분석해, 그룹별 평균 나이로 대체함 

```python
data['Initial'] = 0
for i in data :
    data.Initial = data.Name.str.extract('([A-Za-z]+)\.')

data.Initial.value_counts()
```

```python
pd.crosstab(data.Initial, data.Sex).T.style.background_gradient(cmap='RdBu')
```

- 지나치게 변수가 세분화된 것도 좋지 않음
- `crosstab`을 보면서, 여성에게만 있는 initial과 남성에게만 있는 initial 확인하여 replace

```python
data['Initial'].replace(['Mlle','Mme','Ms','Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don'],['Miss','Miss','Miss','Mr','Mr','Mrs','Mrs','Other','Other','Other','Mr','Mr','Mr'],inplace=True)
```

- Initial에 따른 특성 확인

```python
data.groupby('Initial')['Age'].mean()
```

- null값을 각 특성별 평균값으로 대체
- fillna()
- 여기서 소개한 방법 말고, fillna 함수 사용하는 것이 더 깔끔할 듯..

  ```python
  data.fillna(
    value=None,
    method=None,
    axis=None,
    inplace=False,
    limit=None,
    downcast=None,
    ) -> Union[ForwardRef('DataFrame'), NoneType]
  ```

```python
data.Age.loc[(data.Age.isnull()) & (data.Initial=='Mr')] = data.Age.loc[data.Initial == 'Mr'].mean()
data.Age.loc[(data.Age.isnull()) & (data.Initial=='Mrs')] = data.Age.loc[data.Initial == 'Mrs'].mean()
data.Age.loc[(data.Age.isnull()) & (data.Initial=='Master')] = data.Age.loc[data.Initial == 'Master'].mean()
data.Age.loc[(data.Age.isnull()) & (data.Initial=='Miss')] = data.Age.loc[data.Initial == 'Miss'].mean()
data.Age.loc[(data.Age.isnull()) & (data.Initial=='Other')] = data.Age.loc[data.Initial == 'Other'].mean()

data.Age.isnull().any()
```

Visualization

- numeric data는 거의 Histogram
- categorical data는 barplot
- numeric-numeric은 scatter plot
- bar-bar는 pytoplot?

```python
f, ax = plt.subplots(1,2,figsize=(20,10))

data.Age.loc[data.Survived==0].plot.hist(ax=ax[0], bins=20, edgecolor='black',)
ax[0].set_title('Survived == 0')
ax[0].set_xticks( list(range(0,85,5)) )

data.Age.loc[data['Survived']==1].plot.hist(ax=ax[1], bins=20, edgecolor='black')
ax[1].set_title('Survived == 1')
ax[1].set_xticks( list(range(0,85,5)) )

plt.show()
```

```python
sns.factorplot('Pclass','Survived',col='Initial',data=data)
plt.show()
```

*_Embarked ; Categorical Value_*

```python
pd.crosstab([data.Embarked, data.Pclass], [data.Sex, data.Survived], margins=True).style.background_gradient(cmap = 'rainbow')
```

Port C에서 생존율이 높게 나옴
- 한번더 시각화로 확인하고 
- 배경지식 검색

```python
sns.factorplot('Embarked', 'Survived', data=data)
fig=plt.gcf()
fig.set_size_inches(5,3)
plt.show()
```

```python
sns.factorplot('Pclass','Survived',hue='Sex',col='Embarked',data=data)
plt.show()
```

_*SibSip ; Discrete Feature*_

```python
pd.crosstab(data.SibSp, data.Survived).style.background_gradient()

pd.crosstab(data.SibSp,data.Pclass).style.background_gradient(cmap='summer_r')
```

```python
f, ax = plt.subplots(1,2,figsize=(20,8))

sns.barplot('SibSp','Survived',data=data,ax=ax[0])
ax[0].set_title('SibSp vs. Survived')

sns.factorplot('SibSp','Survived',data=data,ax=ax[1])
ax[1].set_title('SibSp vs. Survived')

plt.show()
plt.close()
```

_*Fare ; Continuous Feature*_

```python
print (data.Fare.mean())
print (data.Fare.max())
print (data.Fare.min())
```

Visualization

- 모든 feature와 파생변수에 대한 visualization은 필수

```python
f, ax = plt.subplots(1,3, figsize=(20,8))

sns.distplot(data.Fare[data['Pclass']==1], ax=ax[0])
ax[0].set_title('Fares in Pclass 1')

sns.distplot(data.Fare[data['Pclass']==2], ax=ax[1])
ax[1].set_title('Fares in Pclass 2')

sns.distplot(data.Fare[data['Pclass']==3], ax=ax[2])
ax[2].set_title('Fares in Pclass 3')

plt.show()
```

- binary / multiple classification 등 자주 나오는 문제들에 대한 전체 pipeline을 함수화하는 것도 좋다
- 시각화를 얼마나 잘하느냐가 Kaggle에서 순위를 결정하기도

### 03. Analyze data

#### Correlation Plot

rebundant한 feature를 없애기 위함
- corr 절대값이 거의 1이 나오는 경우

```python
sns.heatmap(data.corr(), annot=True, cmap='RdYlGn', linewidth=0.2)
plt.gcf().set_size_inches(10,8)
plt.show()
```

correlation 계산

- default = Pearson correlation coefficient

```python
sns.heatmap(
    data,
    vmin=None,
    vmax=None,
    cmap=None,
    center=None,
    robust=False,
    annot=None,
    fmt='.2g',
    annot_kws=None,
    linewidths=0,
    linecolor='white',
    cbar=True,
    cbar_kws=None,
    cbar_ax=None,
    square=False,
    xticklabels='auto',
    yticklabels='auto',
    mask=None,
    ax=None,
    **kwargs,
)
```

#### 파생변수 생성

- family size, alone
- fair range 등

_*여기까지 데이터 분석*_

_*이후 Machine Learning*_